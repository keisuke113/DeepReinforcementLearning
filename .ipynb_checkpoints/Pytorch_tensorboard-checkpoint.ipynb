{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\qoolo\\anaconda3\\envs\\rl_env\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# デフォルトでは `log_dir` としていますが、今回は \"runs\" とさらに具体的な実験名まで記載します\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 24392), started 0:08:28 ago. (Use '!kill 24392' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-457618067166294b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-457618067166294b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs/fashion_mnist_experiment_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 24392), started 0:08:40 ago. (Use '!kill 24392' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-357509d6765b8692\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-357509d6765b8692\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs/fashion_mnist_experiment_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日本語訳追記：本セルを追加しないと以下のセルでエラーが発生するため追加\n",
    "# https://github.com/pytorch/pytorch/issues/30966\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "#def select_n_random(data, labels, n=500):  # 日本語訳注：500は多いので減らす\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 25412), started 0:09:15 ago. (Use '!kill 25412' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fbddb7c516b8a760\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fbddb7c516b8a760\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs/fashion_mnist_experiment_1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qoolo\\anaconda3\\envs\\rl_env\\lib\\site-packages\\torch\\autograd\\__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 24392), started 0:12:16 ago. (Use '!kill 24392' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d37317a52aea66ab\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d37317a52aea66ab\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs/fashion_mnist_experiment_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 24392), started 0:12:24 ago. (Use '!kill 24392' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f1d14acb280008e3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f1d14acb280008e3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs/fashion_mnist_experiment_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
